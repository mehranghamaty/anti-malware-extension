import requests
import lxml
from bs4 import BeautifulSoup
import os

headers = {
  'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36 QIHU 360SE'
}

download_folder = '../foss/'
if not os.path.exists(download_folder):
    os.makedirs(download_folder)

categories= []
url = "https://www.fosshub.com"

f = requests.get(url, headers=headers)
soup = BeautifulSoup(f.content, 'lxml')
categories = soup.find_all('a', {
    'class': 'l-cta'
  })

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

class SeleniumDriver():
    _downloadXPath = "//*[@itemprop=\"downloadUrl\"]"
    def __init__(self, downloadTo):
        options = Options()
        prefs = {
            "download.default_directory" : downloadTo,
            "download.prompt_for_download" : False
        }
        options.add_experimental_option("prefs",prefs)

        self._driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
        
        #service = Service(executable_path="chromedriver.exe")
        #self._driver = webdriver.Chrome(service=service, options=options)

    def getApps(self, url):
        self._driver.get(url)
        apps = self._driver.find_elements(By.XPATH, self._downloadXPath)
        for app in apps:
            app.click()

    def close(self):
        self._driver.close()

webdriver = SeleniumDriver(download_folder)

for cat in categories:
    catlink = cat['href']
    category_url = f"{url}{catlink}"
    print(f"Checking {category_url}")
    f = requests.get(category_url, headers=headers)
    cat_soup = BeautifulSoup(f.content, 'lxml')

    app_links = cat_soup.find_all('a', {'class' : 'app__cta'})
    
    for app in app_links:
        app_url = f"{url}{app['href']}"
        f = requests.get(app_url, headers=headers)
        app_soup = BeautifulSoup(f.content, 'lxml')
        exes = app_soup.find_all('a', {'data-download': 'true'})
        for exe_link in exes:
            download_uri = exe_link['href']
            webdriver.getApps(download_uri)
            """
            f = requests.get(download_uri, headers=headers)
            app_name = download_uri[download_uri.rfind('=')+1:]
            with open(f"{download_folder}{app_name}", 'wb') as download_file:
                download_file.write(f.content)
            """


