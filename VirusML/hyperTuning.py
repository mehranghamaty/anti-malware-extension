"""
    From the baseline methods i'm going to see if I can beat them with some more tuning.
"""
from sklearn.ensemble import RandomForestClassifier
from helpers import getDataset, accuracy
import matplotlib.pyplot as plt
import multiprocessing as mp

datasetpath = './archive/'

(trainX, trainY, testX, testY) = getDataset(datasetpath)

nTrees = [10, 20, 100, 200, 500]

def getAcc(crit: str) -> list[float]:
    #found n_jobs afterwords
    estimator = RandomForestClassifier(warm_start=True, criterion=crit, n_jobs=-1)
    results = []
    for nTree in nTrees:
        estimator.set_params(n_estimators=nTree)
        estimator.fit(trainX, trainY)
        hatY = estimator.predict(testX)
        acc=accuracy(hatY, testY)
        results.append(acc)
    return results

crits = ['gini', 'entropy', 'log_loss']
res = {}
with mp.Pool(len(crits)) as p:
    accs = p.map(getAcc, crits)
    for i in range(len(accs)):
        res[crits[i]] = accs[i]

print(res)
plt.figure()
for crit in res.keys():
    plt.plot(nTrees, res[crit], label=crit)
plt.xlabel("number of trees")
plt.ylabel("Accuracies")
plt.legend()
plt.show()